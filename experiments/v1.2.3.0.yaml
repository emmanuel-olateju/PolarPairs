baseline: v1.0.3, v1.1.3
description: 'Non-Matching Encoder Pairs: performance of distilled-BERT as anchor,
  and deberta-small as fine-tuned model compared across languages'
name: v1.2.3.0
parameters:
  AnchorModel: olateju/PolarPairs-v1.0.3_eng
  Hyperparameter:
    alignment_lr: 0.005
    alignment_normalization: false
    alignment_resnet: false
    encoder_lr: 0.005
    epochs: 3
    eval_batch_size: 8
    eval_strategy: epoch
    lambda: 0.1
    learning_rate: 0.0001
    max_length: 128
    subset_size: 2
    tau: 0.07
    train_batch_size: 8
  Performance:
    amh+eng_multilingual+FT_results:
      src_lang: eng
      src_performance:
        eval_f1_macro: 0.39896588538214095
        eval_f1_weighted: 0.49907814184082677
        eval_loss: 0.6912165284156799
        eval_model_preparation_time: 0.0028
        eval_runtime: 15.9513
        eval_samples_per_second: 201.99
        eval_steps_per_second: 25.264
      tgt_lang: eng
    amh_multilingual+FT_results:
      src_lang: amh
      src_performance:
        epoch: 3.0
        eval_f1_macro: 0.5487400147119244
        eval_f1_weighted: 0.6165331324934694
        eval_loss: 0.6643821597099304
        eval_runtime: 3.1719
        eval_samples_per_second: 210.282
        eval_steps_per_second: 26.482
      tgt_lang: eng
    hau+eng_multilingual+FT_results:
      src_lang: eng
      src_performance:
        eval_f1_macro: 0.3956644268237214
        eval_f1_weighted: 0.49140262731617707
        eval_loss: 1.029404878616333
        eval_model_preparation_time: 0.0027
        eval_runtime: 16.8271
        eval_samples_per_second: 191.477
        eval_steps_per_second: 23.949
      tgt_lang: eng
    hau_multilingual+FT_results:
      src_lang: hau
      src_performance:
        epoch: 3.0
        eval_f1_macro: 0.8042725149426803
        eval_f1_weighted: 0.9180034648254333
        eval_loss: 0.32301512360572815
        eval_runtime: 3.5866
        eval_samples_per_second: 203.812
        eval_steps_per_second: 25.651
      tgt_lang: eng
    swa+eng_multilingual+FT_results:
      src_lang: eng
      src_performance:
        eval_f1_macro: 0.5515083091746023
        eval_f1_weighted: 0.5508678834984725
        eval_loss: 0.7202200889587402
        eval_model_preparation_time: 0.0027
        eval_runtime: 16.1911
        eval_samples_per_second: 198.998
        eval_steps_per_second: 24.89
      tgt_lang: eng
    swa_multilingual+FT_results:
      src_lang: swa
      src_performance:
        epoch: 3.0
        eval_f1_macro: 0.758354285480673
        eval_f1_weighted: 0.7583472479787876
        eval_loss: 0.5296019911766052
        eval_runtime: 6.577
        eval_samples_per_second: 212.711
        eval_steps_per_second: 26.608
      tgt_lang: eng
  Preprocessing:
    tokenizer: microsoft/deberta-v3-small
  language:
  - amh
  - eng
  - hau
  - swa
  model_name: microsoft/deberta-v3-small
